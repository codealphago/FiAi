{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2212, 640) (2212, 5) (553, 640) (553, 5)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "from lib import FiData as data\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from __future__ import division\n",
    "from __future__ import print_function  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "start_date = dt.date(2005,5,1)\n",
    "end_date = dt.date(2016,12,31)\n",
    "rolldays = 40\n",
    "factor_nums = 16\n",
    "label_nums = 5\n",
    "\n",
    "# X,Y = data.get_data(data.Idx_hs300,start_date,end_date,norm=False)\n",
    "# X = data.data_roll(X,rolldays)\n",
    "# Y = Y[rolldays:]\n",
    "# Y = data.get_label5(Y) ## 根据label nums 替换\n",
    "\n",
    "# np.save(\"data/\"+data.Idx_hs300+\"_X.npy\",X)\n",
    "# np.save('data/'+data.Idx_hs300+'_Y.npy',Y)\n",
    "\n",
    "X = np.load('data/'+data.Idx_hs300+'_X.npy')\n",
    "Y = np.load('data/'+data.Idx_hs300+'_Y.npy')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "xs_train = x_train\n",
    "ys_train = sess.run(tf.one_hot(y_train,label_nums))\n",
    "xs_test = x_test\n",
    "ys_test = sess.run(tf.one_hot(y_test,label_nums))\n",
    "sess.close()\n",
    "print (xs_train.shape, ys_train.shape,xs_test.shape,ys_test.shape)\n",
    "# ys = sess.run(tf.reshape(ys,[len(ys),label_nums]))\n",
    "# ys_test = sess.run(tf.reshape(ys_test,[len(ys_test),label_nums]))\n",
    "# x_train[0:1],y_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327306\n"
     ]
    }
   ],
   "source": [
    "# 简单 softmax\n",
    "x = tf.placeholder(\"float\", [None, rolldays*factor_nums])\n",
    "W = tf.Variable(tf.zeros([rolldays*factor_nums,label_nums]))\n",
    "b = tf.Variable(tf.zeros([label_nums]))\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "y_ = tf.placeholder(\"float\", [None,label_nums])\n",
    "# 成本函数, 交叉熵\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "# 变量初始化\n",
    "init = tf.global_variables_initializer()\n",
    "# 开始会话\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "sess.run(train_step,feed_dict={x: xs_train, y_: ys_train})\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "result = sess.run(accuracy, feed_dict={x: xs_test, y_: ys_test})\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN setup finished\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001 # 学习速率，\n",
    "training_iters = 20 # 训练次数\n",
    "batch_size = 1024 # 每次计算数量 批次大小\n",
    "display_step = 10 # 显示步长\n",
    "\n",
    "# Network Parameters\n",
    "n_input = rolldays*factor_nums # 40天×17多因子\n",
    "n_classes = label_nums # 根据涨跌幅度分成7类别\n",
    "# 这里注意要使用 one-hot格式，也就是如果分类如3类 -1,0,1 则需要3列来表达这个分类结果，3类是-1 0 1 然后是哪类，哪类那一行为1 否则为0\n",
    "dropout = 0.8 # Dropout, probability to keep units\n",
    "\n",
    "# tensorflow 图 Graph 输入 input，这里的占位符均为输入\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "# 5 层 CNN 提取特征向量\n",
    "# Store layers weight & bias\n",
    "def CNN_Net_five(x,weights,biases,dropout=0.8,m=1):\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1,rolldays,factor_nums,1])\n",
    "    \n",
    "    # 卷积层1\n",
    "    x = tf.nn.conv2d(x, weights['wc1'], strides=[1,m,m,1],padding='SAME')\n",
    "    x = tf.nn.bias_add(x,biases['bc1'])\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    # 卷积层2 \n",
    "    x = tf.nn.conv2d(x, weights['wc2'], strides=[1,m,m,1],padding='SAME')\n",
    "    x = tf.nn.bias_add(x,biases['bc2'])\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    # 卷积层3 \n",
    "    x = tf.nn.conv2d(x, weights['wc3'], strides=[1,m,m,1],padding='SAME')\n",
    "    x = tf.nn.bias_add(x,biases['bc3'])\n",
    "    x = tf.nn.relu(x)    \n",
    "    \n",
    "    # 卷积层4 \n",
    "    x = tf.nn.conv2d(x, weights['wc4'], strides=[1,m,m,1],padding='SAME')\n",
    "    x = tf.nn.bias_add(x,biases['bc4'])\n",
    "    x = tf.nn.relu(x) \n",
    "    \n",
    "    # 卷积层5 \n",
    "    x = tf.nn.conv2d(x, weights['wc5'], strides=[1,m,m,1],padding='SAME')\n",
    "    x = tf.nn.bias_add(x,biases['bc5'])\n",
    "    x = tf.nn.relu(x) \n",
    "    \n",
    "    # 全连接层\n",
    "    x = tf.reshape(x,[-1,weights['wd1'].get_shape().as_list()[0]])\n",
    "    x = tf.add(tf.matmul(x,weights['wd1']),biases['bd1'])\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    # Apply Dropout\n",
    "    x = tf.nn.dropout(x,dropout)\n",
    "    # Output, class prediction\n",
    "    x = tf.add(tf.matmul(x,weights['out']),biases['out'])\n",
    "    return x\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 16])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 16, 32])),\n",
    "    'wc3': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wc4': tf.Variable(tf.random_normal([5, 5, 64, 32])),\n",
    "    'wc5': tf.Variable(tf.random_normal([5, 5, 32, 16])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([n_input*16, batch_size])),\n",
    "    'out': tf.Variable(tf.random_normal([batch_size, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([16])),\n",
    "    'bc2': tf.Variable(tf.random_normal([32])),\n",
    "    'bc3': tf.Variable(tf.random_normal([64])),\n",
    "    'bc4': tf.Variable(tf.random_normal([32])),\n",
    "    'bc5': tf.Variable(tf.random_normal([16])),\n",
    "    'bd1': tf.Variable(tf.random_normal([batch_size])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# 模型优化\n",
    "pred = CNN_Net_five(x,weights,biases,dropout=keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "correct_pred = tf.equal(tf.argmax(pred,1),tf.arg_max(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "print(\"CNN setup finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0  Minibatch Loss=  279256924160.000000 , Training Accuracy=  0.32731\n",
      "Iter  1  Minibatch Loss=  109534486528.000000 , Training Accuracy=  0.31284\n",
      "Iter  2  Minibatch Loss=  216410046464.000000 , Training Accuracy=  0.31284\n",
      "Iter  3  Minibatch Loss=  66846429184.000000 , Training Accuracy=  0.31284\n",
      "Iter  4  Minibatch Loss=  73142820864.000000 , Training Accuracy=  0.25497\n",
      "Iter  5  Minibatch Loss=  81957363712.000000 , Training Accuracy=  0.32369\n",
      "Iter  6  Minibatch Loss=  42042769408.000000 , Training Accuracy=  0.31826\n",
      "Iter  7  Minibatch Loss=  37998907392.000000 , Training Accuracy=  0.31284\n",
      "Iter  8  Minibatch Loss=  67042140160.000000 , Training Accuracy=  0.31284\n",
      "Iter  9  Minibatch Loss=  29082935296.000000 , Training Accuracy=  0.29295\n",
      "Iter  10  Minibatch Loss=  37004644352.000000 , Training Accuracy=  0.32731\n",
      "Iter  11  Minibatch Loss=  37719105536.000000 , Training Accuracy=  0.26221\n",
      "Iter  12  Minibatch Loss=  16831719424.000000 , Training Accuracy=  0.26582\n",
      "Iter  13  Minibatch Loss=  22338146304.000000 , Training Accuracy=  0.28029\n",
      "Iter  14  Minibatch Loss=  20990492672.000000 , Training Accuracy=  0.32369\n",
      "Iter  15  Minibatch Loss=  10223510528.000000 , Training Accuracy=  0.29656\n",
      "Iter  16  Minibatch Loss=  9384879104.000000 , Training Accuracy=  0.27667\n",
      "Iter  17  Minibatch Loss=  9231187968.000000 , Training Accuracy=  0.32550\n",
      "Iter  18  Minibatch Loss=  13303341056.000000 , Training Accuracy=  0.30380\n",
      "Iter  19  Minibatch Loss=  13856580608.000000 , Training Accuracy=  0.33273\n",
      "保持变量\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# 更改数据格式，降低均值\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(training_iters):\n",
    "        for i in range(int(len(xs_train)/batch_size)):    \n",
    "            batch_x = xs_train[i*batch_size:(i+1)*batch_size]\n",
    "            batch_y = ys_train[i*batch_size:(i+1)*batch_size]\n",
    "            #print(i,batch_size,batch_x.shape,batch_y.shape)\n",
    "            sess.run(optimizer,feed_dict={x:batch_x,y:batch_y,keep_prob:dropout})\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: xs_test,y: ys_test,keep_prob: 1.})\n",
    "        print(\"Iter \" ,step , \" Minibatch Loss= \" , \"{:.6f}\".format(loss) , \", Training Accuracy= \" , \"{:.5f}\".format(acc))\n",
    "    save_path = saver.save(sess,'data/test_var.ckpt')\n",
    "    print ('保持变量')\n",
    "    print(\"Optimization Finished!\")   \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.351266 --- 0.332731\n"
     ]
    }
   ],
   "source": [
    "#预测\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess,'data/test_var.ckpt')\n",
    "#     trainX_Convolution = sess.run(tmp, feed_dict={x:xs_train, keep_prob:1.})\n",
    "    # 经过卷积处理的特征向量\n",
    "    nn_score = sess.run(accuracy,feed_dict={x:xs_train,y: ys_train,keep_prob:1.})\n",
    "    nn_score1 = sess.run(accuracy,feed_dict={x:xs_test,y: ys_test, keep_prob:1.})\n",
    "    print(nn_score,'---',nn_score1)\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": false,
   "environment": null,
   "summary": "fi mondel share",
   "url": "https://anaconda.org/leimon/fimodel2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
